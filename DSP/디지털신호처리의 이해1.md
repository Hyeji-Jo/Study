# 0. 개요
## Sound
- 소리는 일반적으로 진동으로 인한 공기의 압축으로 생성
- 압축이 얼마나 됬느냐에 따라서 표현되는것이 **wave(파동)**
  - 파동은 진동하며 공간/매질을 전파해 나가는 현상
  - 파동이 전파할 때 매질은 움직이지 않는다
  - 파동은 눈으로 볼 수 없다
- 파동을 통해 얻을 수 있는 정보 3가지 (파형그래프를 통해 나타낼 수 있음)
  ![image](https://github.com/user-attachments/assets/b3967b6a-b9b2-4321-babf-b9f2c815d24a)

  - Phase(Degress of displacement) : 위상
  - Amplitude(Intensity) : 진폭(소리의 크기와 관련)
  - Frequency : 주파수(소리의 높낮이)

### Phase(위상)
![image](https://github.com/user-attachments/assets/3171f171-a058-4837-aa31-d7798f39235a)

- **동일 주파수**에서 얼마나 어긋나있는가
  - 파동이 처음 시작하는 위치를 기준으로 다른 지점에서 파동이 얼마나 이동했는지 
- 출발 위치를 결정할 수 있는 값
- 위상은 각도로 나타내며, 일반적으로 **도(degree)** 나 **라디안(radian)** 으로 표현
  - 한 주기는 360도(또는 2π 라디안) 
- v1 = sin(wt) -> v2 = **sin(wt-$\theta$)**
  - theta만큼 뒤처지면 -, 빠르면 + 

### Amplitude(진폭)
![image](https://github.com/user-attachments/assets/f861c9a7-1530-4647-949f-6387e45c5bc9)

- **파동의 높이**로 이해할 수 있음
- 소리의 경우 진폭이 크면 소리가 더 크고, 진폭이 작으면 소리가 작게 들림
  - 음압이 높아질수록 공기의 진동이 커지기 때문에 사람의 귀에 더 크게 들림
- 파동이 가진 에너지를 나타냄
  - 진폭이 클수록 파동이 전달하는 에너지가 커짐
  - 진폭이 큰 물결은 더 강한 힘으로 해안에 부딪힐 수 있음
- 사인파, 코사인파와 같은 주기적 파동에서는 진폭이 **파동의 최고점과 최저점 간의 거리를 절반으로 나눈 값**
- 진폭의 변화를 통해 감정, 말투, 강세 등을 분석할 수 있음
  - 진폭이 갑자기 커진다면 화를 내는 감정이나 흥분 상태임을 유추가능
- sin(wt) -> **3sin(wt)**

### Frequency(주파수)
![image](https://github.com/user-attachments/assets/079ae6ad-759a-453a-8af8-57456be5c2ea)

- **파동이 1초 동안 반복되는 횟수**
- 보통 **헤르츠(Hz)** 단위 사용
- 주파수가 높을수록 파동이 빠르게 반복되고, 낮을수록 느리게 반복
  - 주파수 100 Hz의 파동은 1초에 100번 진동하는 것
- **소리의 높이**를 결정하는 중요한 요소
  - 높은 주파수는 높은 음(고음)을 생성, 낮은 주파수는 낮은 음(저음)을 생성
  - 남성의 목소리는 대체로 저주파, 여성의 목소리는 고주파 성분을 더 많이 포함
- 인간이 들을 수 있는 주파수의 범위 : 20 Hz에서 20,000 Hz(20 kHz)까지 - 가청 주파수
- **주파수와 파장은 서로 반비례 관계**
  - 주파수가 높을수록 파장은 짧아지고, 낮을수록 파장은 길어짐
- **주기와 주파수는 역수 관계**
  - 주기 = 1/주파수 
- sin(wt) -> **sin(3wt)**

## Audio Task
- Sound
  - Sound Classification & Auto-tagging
    - ex) 다양한 기계로부터 수집한 사운드를 통해 어느 위치에 있는지 파악하는 프로젝트 
- Speech
  - Speech Recognition(STT) - 음성인식
    - 음성을 인식하여 나오는 텍스트가 사용될 곳이 많음
    - LAS 모델이 유명
    - 딥러닝 시대 이후로는 End-to-end 모델로 나아가고 있음
  - Speech Synthesis(TTS) - 음성합성
    - Tacotron 모델이 유명 
  - Speech Style Transfer(STS) - 음성변환

- Sound와 Speech의 차이
  - Sound
    - 일반적인 물리적 현상
    - 꼭 의미를 가질필요 없으며, 사람, 동물, 물체, 자연현상 등 다양한 원천에서 발생 가능
  - Speech
    - 의미를 전달하기 위한 사람의 음성 신호
      - 사람이 특정한 언어를 통해 의사를 표현하기 위해 만들어낸 소리    


## Computer가 소리를 이해하는 과정
- 연속적인 아날로그 신호를 **표본화(Sampling), 양자화(Quantizing), 부호화(Encoding)** 을 거쳐 **이진 디지털 신호(Binary Digital Signal)로 변화**시켜 인식

- **표본화(Sampling)**
  - 샘플링 단계에서 초당 샘플링 횟수를 정하는데, 이를 Sampling rate라고 함
  - 1초의 연속적인 시그널을 몇개의 숫자로 표현 할 것인가?
  - 샘플링 레이트가 최대 frequency의 2배 보다 커져야 한다는 것
    - 𝑓𝑠>2𝑓𝑚  여기서  𝑓𝑠 는 sampling rate, 그리고  𝑓𝑚 은 maximum frequency
    - Nyqusit rate = 2𝑓𝑚
    - Nyqusit frequency =  𝑓𝑠/2 , sampling rate의 절반
  - 일반적으로 Sampling은 인간의 청각 영역에 맞게 형성됨
    - Audio CD : 44.1 kHz(44100 sample/second)
    - Speech communication : 8 kHz(8000 sample/second)  
- **양자화(Quantizing)**
  - 양자화 단계에서는 amplitude의 real valued를 기준으로 시그널의 값을 조절
  - Amplitude를 이산적인 구간으로 나누고, signal 데이터의 amplitude를 반올림하게 됨

### 표본화(Sampling)
![image](https://github.com/user-attachments/assets/4fcd0f46-e926-475a-9eb5-1004ff34efba)

- 연속적인 아날로그 신호를 이산적인 디지털 신호로 변환하는 과정
![image](https://github.com/user-attachments/assets/76d19ec2-6968-41a1-8795-5f0385e158db)

- 신호를 측정하는 간격 = Sampling rate
  - 높을수록 음질이 더 좋다
- **나이퀴스트 샘플링 이론(Nyquist Sampling Theorem)** 에 근거
  - 원본 신호의 최대 주파수의 2배 이상이어야 함
  - aliasing 방지를 위한 이론
![image](https://github.com/user-attachments/assets/b46a981d-92ef-4a3e-bc86-87835a1851e0)
- Sampling rate 값이 너무 작으면 **Aliasing** 문제 발생

### Aliasing
![image](https://github.com/user-attachments/assets/47ae2458-c91a-4bb6-882c-e2bb6d43072c)

- 신호를 샘플링할 때 샘플링 레이트가 충분히 높지 않아 생기는 왜곡 현상
- 샘플링 주파수가 신호의 최대 주파수 성분의 두배보다 낮을 때 발생
- 표본화 과정에서 원신호를 정상적으로 복원하지 못하고 일그러짐이 발생하는것
- 즉, 신호의 왜곡이 발생
- **방지 방법**  
  - **적절한 샘플링 레이트 사용** : 원본 신호의 최대 주파수의 2배 이상 샘플링 레이트를 선택
  - **반올림 필터(Anti-Aliasing Filter)** : 샘플링 전에 신호의 고주파 성분을 제거하는 저역 통과 필터를 사용하는 방법

### 반올림 필터(Anti-Aliasing Filter)
- 신호를 샘플링하기 전에 고주파 성분을 제거하여 에일리어싱(Aliasing)을 방지하는 필터
- 저역 통과 필터(Low-pass Filter)로 구현되며, 샘플링 주파수의 절반 이상인 주파수 성분을 걸러냄
- 반올림 필터는 신호의 고주파 성분을 제거하면서, 신호를 더 스무드하게 만듬
  - 사람이 필요로 하지 않거나 신호 복원에 방해되는 고주파 성분만을 제거하는 것
  - 전체 음질이나 의미를 크게 훼손하지 않도록 설계
  - 그리고 제거 되더라도 보통 인간이 인지하지 못할 정도로 미미한 수준 


# 1. Digital Signal Processing
- 목적 : 소리 signal를 어떠한 데이터 타입으로 표현하며, 소리와 관련된 task를 해결
```py
# 필요 패키지 설치
!pip install torch
!pip install torchaudio

# 패키지 로드
import librosa
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import torch
import torchaudio

# 데이터셋 다운로드
test_dataset = torchaudio.datasets.LIBRISPEECH("./", url="test-clean", download=True)

# 데이터 확인
test_dataset[1] # (tensor([오디오 샘플 데이터]), 샘플링 주파수, 메타데이터)
# (tensor([0.123, -0.234, ...]), 16000, {'utterance_id': '19', 'speaker_id': '103', 'chapter_id': '5', 'transcription': 'Hello, world!', 'original_text': 'Hello, world!'})

# duration 계산 - 오디오 신호의 재생 시간을 초 단위로 계산 (오디오 샘플 데이터 수 / sampling rate)
audioData = test_dataset[1][0][0]
sr = test_dataset[1][1]
len(audioData) / sr

# 오디오 표시
import IPython.display as ipd
ipd.Audio(audioData, rate=sr)
```
