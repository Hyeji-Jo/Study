# 0. 화자 분할 (Speaker Diarization)이란?
- 오디오를 **화자 단위**로 구분하여 **“누가 언제 말했는가?”(Who Speaks When?)** 를 결정하는 작업

# 1. NeMo 기반 Speaker Diarization 시스템 구성
<img width="705" alt="image" src="https://github.com/user-attachments/assets/50c256eb-3fc6-46d3-b0f7-e2df7bbfac1d" />

## 1) 음성 활동 검출 (Voice Activity Detection, VAD)
- VAD 모델을 사용하여 음성이 있는 구간을 찾고 타임스탬프 생성
- 배경 소음은 무시하고, 말하는 구간만 식별
- NeMo에서는 **MarbleNet** 모델을 사용하여 VAD 수행
- **두 가지 방식의 VAD 지원** : **Oracle VAD (오라클 VAD) / System VAD (시스템 VAD)**
  
### Oracle VAD (오라클 VAD)
- 실제(ground-truth) 음성/비음성 라벨을 사용하여 VAD를 수행하는 방식
- 즉, 이미 제공된 정답 데이터(음성이 있는 부분과 없는 부분의 **타임스탬프**)를 활용 -> **NeMo의 사전 학습된 화자 임베딩 추출 모델 활용**
- 오라클 VAD를 사용하면 VAD 모델의 성능에 영향을 받지 않고 화자 분할을 평가할 수 있음
  
### System VAD (시스템 VAD)
- 실제 VAD 모델을 사용하여 음성/비음성 라벨을 생성하는 방식
- 즉, NeMo의 VAD 모델이 음성이 있는 구간을 직접 예측하여 이를 기반으로 화자 분할 수행
- **Ground-truth 데이터가 없을 때** 사용 가능
  
  
## 2) 분할 (Segmentation)
- VAD에서 찾은 음성 구간을 더 작은 조각으로 나누어 분석
  
### 균일한 분할 (Uniform Segmentation)
- VAD(음성 활동 검출) 모듈을 거친 후, 음성을 여러 개의 짧은 세그먼트(0.5~3.0초) 로 분할
- 각 세그먼트에서 화자 임베딩(Speaker Embedding)을 추출
- 각 세그먼트의 임베딩을 통해 해당 구간에서 화자의 특징(프로필, Representation) 을 얻을 수 있음
  
### 세그먼트 길이의 트레이드오프 (Trade-off: Long vs Short Segment Length)
- 세그먼트 길이를 설정할 때 **화자 표현(Representation) 품질**과 **시간 해상도(Temporal Resolution)** 사이의 트레이드오프가 존재
  - 긴 세그먼트 (2 ~ 3초 이상)
    - 화자의 특성을 더 명확하게 추출할 수 있으며 보다 일관된 화자 표현 가능
    - 2~3초 동안 한 명의 화자로 단정할 경우 오류 발생
    - 화자가 바뀌는 지점을 정확히 잡아내기 어려움
  - 짧은 세그먼트 (0.2 ~ 0.5초)
    - 시간 해상도가 높아져 보다 세밀한 분석 가능
    - 너무 짧아 신뢰할 수 있는 화자 특징 추출이 어려움 
  
### 다중 스케일 분할 (Multi-scale Segmentation)
<img width="699" alt="image" src="https://github.com/user-attachments/assets/864783e3-2fb6-4373-8829-ba9389cb2f64" />

- **NeMo** 화자 분할 파이프라인에서는 이러한 문제를 해결하기 위해 다중 스케일 접근법 사용
- 여러 개의 세그먼트 길이를 사용하여 분석하고, **각 스케일에서 얻은 결과를 융합(Fusion)하여 최종 결론 도출**
  - 여러 개의 서로 다른 세그먼트 길이를 조합하여 화자를 분석
  - 각각의 세그먼트 길이에서 얻은 affinity(유사도) 값을 결합(Fuse)하여 최종 결과 생성 
  
  
## 3) 화자 임베딩 추출 (Speaker Embedding Extraction)
- TitaNet-L 모델을 사용하여 각 화자의 고유한 특징을 벡터(임베딩)로 변환

## 4) 클러스터링 (Clustering)
- 화자 임베딩 벡터를 군집화하여 **화자의 수를 추정**
- 같은 화자가 말한 구간을 같은 그룹으로 묶음

## 5) 신경망 기반 다이어라이저 (Neural Diarizer)
- MSDD (Multi-Scale Diarization Decoder)를 활용하여 클러스터링 결과를 기반으로 최종 화자 라벨 생성
- 여러 화자가 동시에 말하는 중첩 음성(overlap speech) 도 처리 가능

## 6) 결과 출력 (Speaker Labels)
- 최종적으로 화자 레이블을 생성하여 오디오 내에서 누가 언제 말했는지 표시
