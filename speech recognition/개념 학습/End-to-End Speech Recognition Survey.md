# 논문 정리 : End-to-End Speech Recognition: A Survey (T-ASLP 2024)

## Abstract
- **딥러닝이 도입된 ASR** 모델이 도입되지 않은 모델과 비교해 **단어 오류율(WER)이 50%이상 감소**
  - **WER** : 음성인식 시스템이 인식한 텍스트가 정답과 얼마나 다른지를 측정하는 평가 지표
    - WER = (I + D + S) / N
    - 추가, 삭제, 대체된 단어 수를 전체 정답 단어 수로 나누어 계산
      - **I (Insertions)**: 추가된 단어 수 (인식 결과에만 존재)
      - **D (Deletions)**: 빠뜨린 단어 수 (정답에 있었는데 인식 결과엔 없음)
      - **S (Substitutions)**: 잘못 인식된 단어 수 (ex. "love" → "like")
      - **N**: 정답 문장의 총 단어 수
    - 낮을수록 좋은 값
  - **CER** : 음성 인식의 오류율을 **문자 단위**로 계산하는 지표
    - 한국어, 중국어 등 공백이 없는 언어에서도 유용
    - WER에 비해 좀 더 세밀한 오류 파악 가능
- 현재는 **End-to-End(E2E)모델이 음성인식의 주 방식**
