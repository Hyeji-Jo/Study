# 논문 정리 : End-to-End Speech Recognition: A Survey (T-ASLP 2024)

## Abstract
- **딥러닝이 도입된 ASR** 모델이 도입되지 않은 모델과 비교해 **단어 오류율(WER)이 50%이상 감소**
  - **WER** : 음성인식 시스템이 인식한 텍스트가 정답과 얼마나 다른지를 측정하는 평가 지표
    - WER = (I + D + S) / N
    - 추가, 삭제, 대체된 단어 수를 전체 정답 단어 수로 나누어 계산
      - **I (Insertions)**: 추가된 단어 수 (인식 결과에만 존재)
      - **D (Deletions)**: 빠뜨린 단어 수 (정답에 있었는데 인식 결과엔 없음)
      - **S (Substitutions)**: 잘못 인식된 단어 수 (ex. "love" → "like")
      - **N**: 정답 문장의 총 단어 수
    - 낮을수록 좋은 값
  - **CER** : 음성 인식의 오류율을 **문자 단위**로 계산하는 지표
    - 한국어, 중국어 등 공백이 없는 언어에서도 유용
    - WER에 비해 좀 더 세밀한 오류 파악 가능
- 현재는 **End-to-End(E2E)모델이 음성인식의 주 방식**

## 1. Introduction
### 전통적인 과정
- 전통적인 통계적 ASR 아키텍처는 네 가지 주요 요소로 구성
  - 음성 오디오 신호로부터의 **음향 특징 추출**
  - **음향 모델링**(acoustic modeling)
  - **언어 모델링**(language modeling)
  - **베이즈 결정 규칙**(bayes decision rule)에 기반한 탐색 과정
- 기존 음향 모델링은 **화자의 발화 속도 변화를 반영**하기 위해 **은닉 마르코프 모델(HMM)** 기반

### 딥러닝 도입 시작
- 음향 모델링과 언어 모델링에 도입 시작
  - 음향 모델링에서는 **가우시안 혼합 모델(GMM)** 을 대체
  - **음향 특징 집합을 확장**(예: 비선형 판별법 또는 tandem 방식)하는 데 사용
  - 언어 모델링에서는 **카운트 기반 방식(예: N-gram)** 이 **딥러닝 기반 언어 모델로 대체**
  - **기존 ASR 아키텍처 자체는 바뀌지 않음**
- **여전히 많은 별도의 구성 요소와 전문 지식에 의존**
  - 음성 신호 전처리
  - 녹음 환경 변화에 대한 견고성 확보 기법
  - 음소 목록과 발음 사전
  - 음소 클러스터링
  - OOV(사전에 없는 단어) 처리
  - 다양한 적응/정규화 방법
  - 복잡한 학습 스케줄 (예: 시퀀스 기반 판별 학습 포함) 등
- **음성 신호 전처리와 특징 추출을 하나의 음향 모델에 통합**하는 접근 제안
- 딥러닝의 도입은 **HMM 기반 전통 ASR 아키텍처를 완전히 대체하려는 연구**들로 이어짐
- **전통적인 음성 처리 모델**을, 더 일반적인 **시퀀스-투-시퀀스 방식의 머신러닝 모델**로 대체
