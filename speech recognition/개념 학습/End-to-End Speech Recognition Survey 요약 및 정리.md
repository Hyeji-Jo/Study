# 논문 정리 : End-to-End Speech Recognition: A Survey (T-ASLP 2024)

## Abstract
- **딥러닝이 도입된 ASR** 모델이 도입되지 않은 모델과 비교해 **단어 오류율(WER)이 50%이상 감소**
  - **WER** : 음성인식 시스템이 인식한 텍스트가 정답과 얼마나 다른지를 측정하는 평가 지표
    - WER = (I + D + S) / N
    - 추가, 삭제, 대체된 단어 수를 전체 정답 단어 수로 나누어 계산
      - **I (Insertions)**: 추가된 단어 수 (인식 결과에만 존재)
      - **D (Deletions)**: 빠뜨린 단어 수 (정답에 있었는데 인식 결과엔 없음)
      - **S (Substitutions)**: 잘못 인식된 단어 수 (ex. "love" → "like")
      - **N**: 정답 문장의 총 단어 수
    - 낮을수록 좋은 값
  - **CER** : 음성 인식의 오류율을 **문자 단위**로 계산하는 지표
    - 한국어, 중국어 등 공백이 없는 언어에서도 유용
    - WER에 비해 좀 더 세밀한 오류 파악 가능
- 현재는 **End-to-End(E2E)모델이 음성인식의 주 방식**

## 1. Introduction
### 전통적인 ASR 시스템 구조
- 전통적인 통계적 ASR 아키텍처는 네 가지 주요 요소로 구성
  - **음향 특징 추출 (Feature Extraction)** : 음성 오디오 신호로부터
  - **음향 모델링 (Acoustic Modeling)** : 주로 HMM, GMM
    - 은닉 마르코프 모델(HMM) : 화자의 발화 속도 변화를 반영
  - **언어 모델링 (Language Modeling)** : **카운트 기반 방식(예: N-gram)**
  - **탐색/디코딩 (Search)** : 베이즈 결정 규칙(bayes decision rule)에 기반한 탐색 과정

### 딥러닝 도입 시작
- 음향 모델에서 **가우시안 혼합 모델(GMM)** 대신 신경망 모델 사용
- 언어 모델도 **딥러닝 기반 언어 모델로 대체**
- 하지만 여전히 파이프라인 구조 자체는 유지

### 여전히 많은 별도의 구성 요소와 전문 지식에 의존
- 음성 신호 전처리
- 녹음 환경 변화에 대한 견고성 확보 기법
- 음소 목록과 발음 사전
- 음소 클러스터링
- OOV(사전에 없는 단어) 처리
- 다양한 적응/정규화 방법
- 복잡한 학습 스케줄 (예: 시퀀스 기반 판별 학습 포함) 등

### 시퀀스-투-시퀀스(sequence-to-sequence)
- 음성 전처리 + 특징 추출 + 음향 모델링 → 통합
- 점점 **sequence-to-sequence** 형태로 발전
- 기존 음성처리 특화 설계 대신 **범용 딥러닝 모델로 처리**
