# 논문 정리 : End-to-End Speech Recognition: A Survey (T-ASLP 2024)

## Abstract
- **딥러닝이 도입된 ASR** 모델이 도입되지 않은 모델과 비교해 **단어 오류율(WER)이 50%이상 감소**
  - **WER** : 음성인식 시스템이 인식한 텍스트가 정답과 얼마나 다른지를 측정하는 평가 지표
    - WER = (I + D + S) / N
    - 추가, 삭제, 대체된 단어 수를 전체 정답 단어 수로 나누어 계산
      - **I (Insertions)**: 추가된 단어 수 (인식 결과에만 존재)
      - **D (Deletions)**: 빠뜨린 단어 수 (정답에 있었는데 인식 결과엔 없음)
      - **S (Substitutions)**: 잘못 인식된 단어 수 (ex. "love" → "like")
      - **N**: 정답 문장의 총 단어 수
    - 낮을수록 좋은 값
  - **CER** : 음성 인식의 오류율을 **문자 단위**로 계산하는 지표
    - 한국어, 중국어 등 공백이 없는 언어에서도 유용
    - WER에 비해 좀 더 세밀한 오류 파악 가능
- 현재는 **End-to-End(E2E)모델이 음성인식의 주 방식**




## 1. Introduction
### 전통적인 ASR 시스템 구조
- 전통적인 통계적 ASR 아키텍처는 네 가지 주요 요소로 구성
  - **음향 특징 추출 (Feature Extraction)** : 음성 오디오 신호로부터
  - **음향 모델링 (Acoustic Modeling)** : 주로 HMM, GMM
    - 은닉 마르코프 모델(HMM) : 화자의 발화 속도 변화를 반영
  - **언어 모델링 (Language Modeling)** : **카운트 기반 방식(예: N-gram)**
  - **탐색/디코딩 (Search)** : 베이즈 결정 규칙(bayes decision rule)에 기반한 탐색 과정


### 딥러닝 도입 시작
- 음향 모델에서 **가우시안 혼합 모델(GMM)** 대신 신경망 모델 사용
- 언어 모델도 **딥러닝 기반 언어 모델로 대체**
- 하지만 여전히 파이프라인 구조 자체는 유지


### 여전히 많은 별도의 구성 요소와 전문 지식에 의존
- 음성 신호 전처리
- 녹음 환경 변화에 대한 견고성 확보 기법
- 음소 목록과 발음 사전
- 음소 클러스터링
- OOV(사전에 없는 단어) 처리
- 다양한 적응/정규화 방법
- 복잡한 학습 스케줄 (예: 시퀀스 기반 판별 학습 포함) 등


### 시퀀스-투-시퀀스(sequence-to-sequence)
- 음성 전처리 + 특징 추출 + 음향 모델링 → 통합
- 점점 **sequence-to-sequence** 형태로 발전
- 기존 음성처리 특화 설계 대신 **범용 딥러닝 모델로 처리**


### End-to-End 정의
- **Cambridge Dictionary**에 따르면, **“end-to-end”**라는 형용사는 **“하나의 과정의 모든 단계를 포함하는 것”** 으로 정의
  - 하나의 과정으로 끝까지 처리되는 음성 인식 모델
- 단순히 구조만 하나가 아닌 모델 구성, 학습 방식, 데이터 활용 등 모든 측면에서 통합된 구조 의미
  - **a) Joint Modeling (통합 모델링)** : 기존의 모듈화된 모델을 하나의 신경망으로 통합
  - **b) Single-Pass Search (단일 탐색 과정)** : 전체 정보를 기반으로 한 번에 결과 예측
    - Search는 모델이 **어떤 출력을 내릴지 탐색**하는 과정 == **디코딩(decoding)**
    - 전통모델 처럼 여러 모듈 따로 돌아가게 하지 않고, **하나의 디코더 블록이 전체 역할을 맡음**
  - **c) Joint Training (통합 학습)** : 하나의 목적함수로 전체 모델 학습 (ex. WER 최소화)
  - **d) Training Data (단일 종류의 학습 데이터)** : 전사된 음성 데이터만으로 학습
    - **전사(transcription)** : 음성 데이터를 듣고, 그 내용을 문자로 적은 것
    - **전사된 음성 데이터** : 음성과 해당 텍스트가 짝을 이루는 데이터
  - **e) Training from Scratch (처음부터 학습)** : 사전 정렬이나 초기 모델 없이 처음부터 학습
    - 과거 음향 모델은 단어의 음소가 몇 초 구간에 위치하는지 미리 알고 있어야 했음 -> **Forced Alignment**로 구함
    - 그런 정렬 정보 없이도 **모델이 직접 정렬도 학습**
  - **f) Secondary Knowledge Sources (2차 지식원 회피)** : 발음 사전, 음소 집합 같은 외부 지식 사용 안함
    - 모델이 직접 문자나 음소 단위의 분포를 학습하고 정렬까지 담당 
    - **일관성 문제, 비용, 오류 가능성** 등을 줄여줌
  - **g) Vocabulary Modeling (어휘 모델링 방식)** : 발음 사전을 사용하지 않으며, 문자/서브워드 기반 사용
    - 전체 단어 기반 모델은 **엄청난 양의 전사 데이터를 필요로 하므로 현실적으로 어려움 존재**
  - **h) Generic vs. Informed Modeling (범용 vs. 특화 모델링)** : 도메인 지식 없이도 데이터로부터 학습
    - **예를 들어, ASR의 순차적(monotonic) 정렬 특성을 attention 기반 모델에서는 학습을 통해, HMM에서는 시스템 구조로 직접 구현**
- 특히 전통적인 ASR의 발음사전, 정렬 정보, 모듈별 최적화 과정을 피하고, 오직 데이터를 기반으로 전체 시스템을 하나의 목표 아래 학습하는 것이 핵심


### ASR 시스템 개발의 목표
- 주 목표
  - 단어 오류율(WER: Word Error Rate) 최소화
- 부차적 목표
  - 디코더의 시간/메모리 복잡도 줄이기
  - 모델링을 쉽게 하고, 다양한 도메인/언어에 적용할 수 있는 범용성 확보 


### End-to-End 이점
- **구조적 단순화와 범용성 (Simplicity & Generality)**
  - 하나의 신경망 구조로 전체 시스템 구성
  - **디코딩**이 단일 모델 안에서 처리되어 **복잡한 모델 통합 불필요**
  - **새로운 언어나 도메인에 대해 빠른 개발 주기 달성**
- **효율성과 경량화 (Efficiency & Lightweight Design)**
  - 메모리, 연산 자원이 줄어들어 임베디드 환경에서의 ASR 적용에도 유리
- **학습 최적화와 안정성 (Learning Optimization & Robustness)**
  - 통합 학습(joint training)으로 잘못된 국소 최적화 지점 피할 수 있음
- **외부 리소스 없이 데이터 기반 학습 (Data-Driven & Resource-Free)**
  - 발음사전과 같은 2차 지식원 불필요
  - 2차 지식원이 잘못된 경우 생기는 오류 방지
  - 충분한 작업-특화 데이터(task-specific data)만 있으면 학습 가능


### 논문의 구성
- 제2장: E2E 음성 인식의 역사적 발전 과정과, **입출력 정렬 방식(alignment)** 관점의 분류
- 제3장: 기본 E2E 모델에 대한 개선 (구조, 문맥, loss 등)
- 제4장: E2E 모델 학습 방법
- 제5장: 다양한 E2E 디코딩 전략
- 제6장: E2E ASR에서의 **언어 모델(LM)** 의 역할과 통합
- 제7장: 최신 E2E 모델과 전통적인 HMM 기반 ASR의 비교
- 제8장: E2E 및 전통 ASR 접근법에 대한 성능 비교
- 제9장: E2E ASR의 실제 적용 사례
- 제10장: E2E ASR 향후 연구 방향
- 제11장: 결론
