# 0. 음성인식 모델의 역사  
음성인식으로 사용자 맥락 파악 -> 맥락에 맞는 음악 추천  

- **1950~1960년대: 초기 연구와 기초 기술**  
  - 1952년, Bell Labs의 Audrey: 가장 초기의 음성인식 시스템 중 하나로, 숫자 0부터 9까지의 음성을 인식할 수 있었습니다.  
  - 1960년대, IBM의 Shoebox: 단어 인식을 위한 시스템으로, 16개의 단어와 숫자를 인식할 수 있었습니다.  
- **1970~1980년대: 동적 시간 왜곡과 히든 마르코프 모델**  
  - 동적 시간 왜곡 (Dynamic Time Warping, DTW): 음성 신호의 시간적 변형을 허용하여 유사성을 측정하는 기법으로, 음성인식에서 널리 사용되었습니다.  
  - 히든 마르코프 모델 (Hidden Markov Model, HMM): 1970년대 후반에 도입되어 1980년대와 1990년대에 음성인식 시스템의 주류가 되었습니다. 음성의 통계적 모델링에 기반한 이 모델은 연속적인 음성을 인식하는 데 뛰어난 성능을 보였습니다.  
- **1990년대: 대규모 음성 데이터와 모델의 발전**  
  - 스피커 독립 음성인식 시스템: 다양한 사용자에게 적용될 수 있는 모델로, 대규모 데이터와 더욱 정교한 HMM이 사용되었습니다.  
  - 연속 음성 인식: 문맥을 고려하여 연속적인 음성을 인식할 수 있게 되었습니다. 이는 특히 IBM의 ViaVoice와 같은 상업용 제품에 적용되었습니다.  
- **2000년대: 통계적 모델과 신경망의 결합**  
  - 조건부 확률 모델 (Conditional Random Fields, CRF) 및 최대 엔트로피 모델: 음성인식의 정확도를 높이기 위해 사용되었습니다.  
  - 딥 뉴럴 네트워크 (DNN): 2000년대 후반부터 HMM과 DNN을 결합한 모델이 사용되기 시작하여, 음성 인식의 성능이 크게 향상되었습니다.  
- **2010년대 이후: 심층 신경망과 음성 비서의 발전**  
  - 딥러닝의 도입: 딥러닝 기술이 음성인식에 도입되면서 음성 인식의 정확도와 효율성이 크게 향상되었습니다. 구글의 음성 검색, 애플의 시리, 아마존의 알렉사 등 주요 음성 비서 서비스가 이 기술을 사용합니다.  
  - 엔드투엔드 모델: RNN, LSTM, GRU와 같은 순환 신경망이 사용되면서, 음성인식 시스템이 더욱 통합되고 정확해졌습니다.  
  - Transformer 기반 모델: 최근에는 Transformer 구조를 사용한 모델이 음성인식에 적용되고 있습니다. 특히, 구글의 WaveNet과 같은 모델이 높은 성능을 보이고 있습니다.  
  이처럼 음성인식 기술은 초기의 간단한 시스템에서부터 복잡한 신경망 기반의 모델에 이르기까지 지속적으로 발전해왔습니다. 최신 기술들은 점점 더 높은 정확도를 제공하며 다양한 응용 분야에서 사용되고 있습니다.  

## 2010년도 이후 사용된 모델  
1.DNN-HMM (Deep Neural Networks - Hidden Markov Model): 2010년대 초반, 딥 뉴럴 네트워크가 음성인식에 도입되면서 HMM과 결합하여 음성 인식의 성능이 크게 향상되었습니다. 이는 구글, 마이크로소프트 등의 대형 기술 기업들이 상용 음성 인식 시스템에 도입한 방법입니다.  

2.RNN (Recurrent Neural Networks): DNN보다 연속된 데이터 처리에 강점이 있는 순환 신경망이 음성인식에 사용되기 시작했습니다. 특히 음성 신호의 시간적 특성을 잘 모델링할 수 있었습니다.  

3.LSTM (Long Short-Term Memory Networks): RNN의 한계를 극복하기 위해 고안된 LSTM은 긴 시퀀스 데이터에서의 학습이 가능하여 음성 인식 성능을 더욱 향상시켰습니다. LSTM은 특히 장기적인 의존성을 처리하는 데 효과적입니다.  

4.GRU (Gated Recurrent Unit): LSTM의 변형으로, 더 간단한 구조와 적은 계산 비용으로 유사한 성능을 제공합니다. GRU는 LSTM보다 계산 효율성이 높아 실시간 음성인식 시스템에 적합합니다.  

5.End-to-End 모델 (CTC - Connectionist Temporal Classification): 음성에서 텍스트로의 직접적인 매핑을 가능하게 하는 엔드투엔드 학습 방법이 도입되었습니다. 이는 RNN과 LSTM을 기반으로 하며, 음성 인식의 복잡성을 줄이고 성능을 높였습니다. 대표적으로 Baidu의 DeepSpeech가 있습니다.  

6.Attention Mechanisms: Transformer의 핵심인 어텐션 메커니즘이 음성인식에 도입되어, 모델이 입력 시퀀스의 중요한 부분에 집중할 수 있게 되었습니다. 이는 더욱 정교한 음성 인식을 가능하게 했습니다.  

7.Transformer 모델: 2017년 구글이 발표한 Transformer 구조는 음성인식에도 적용되어 큰 성능 향상을 이루었습니다. Transformer는 병렬 처리가 가능하여 더 빠르고 정확한 인식이 가능합니다.  

8.BERT (Bidirectional Encoder Representations from Transformers): BERT와 같은 사전 훈련된 언어 모델이 음성인식에 도입되어, 맥락 이해 능력이 향상되었습니다. 이는 특히 자연어 처리와 결합된 음성인식 시스템에서 강력한 성능을 발휘합니다.  

9.Conformer (Convolutional + Transformer): 2020년대 초반, Conformer 모델은 CNN과 Transformer를 결합하여 음성 인식의 정확도를 더욱 높였습니다.   Conformer는 음성 신호의 로컬 패턴을 잘 포착하는 CNN과 글로벌 의존성을 잘 포착하는 Transformer의 장점을 결합한 모델입니다.  

10.WaveNet 및 VQ-VAE: 구글의 WaveNet과 같은 모델은 고품질 음성 합성을 가능하게 했고, 이는 음성 인식의 사전 처리 과정에서도 활용되었습니다. 또한, VQ-VAE(벡터 양자화 변형 오토인코더)와 같은 모델은 음성 데이터를 효율적으로 인코딩하고 복원하는 데 사용되었습니다.  

# 1. Digital Signal Processing  
## Sound  
- 소리 = 진동으로 인한 공기의 압축  
- 압축이 얼마나 됬느냐 = Wave(파동)  
  - 진동하며 공간/매질을 전파해 나가는 현상  
- 소리에서 얻을 수 있는 물리량     
  - Phase(Degress of displacement) : 위상  
  - Amplitude(Intensity) : 진폭    
  - Frequency : 주파수  
- 물리 음향  
  - Intensity : 소리 진폭의 세기  
  - Frequency : 소리 떨림의 빠르기  
  - Tone-Color : 소리 파동의 모양  
- 심리 음향  
  - Loudness : 소리 크기  
  - Pitch : 음정, 소리의 높낮이 / 진동수  
  - Timbre : 음색, 소리 감각  
 
## Fourier Transform (푸리에 변환)   
- 임의의 입력 신호를 다양한 주파수를 갖는 주기함수(복수 지수함수)들의 합으로 분해하여 표현하는 것  
- 푸리에 변환의 결과값으로 주파수의 강도와 주파수의 위상을 얻게 됨  

# 2. Audio Task  
- Sound  
  - Speech Classification & Auto-tagging  
- Speech  
  - Speech Recognition(STT) - 음성 인식  
  - Speech Synthesis(TTS) - 음성 합성  
  - Speech Style Transfer(STS) - 음성 변환  

스마트 스피커의 경우 사용자가 말하는 것을 음성인식으로 들어 txt를 자연어 처리로 넘김  
자연어 처리팀에서 맞는 정보를 return해주고, 그 정보를 음성 합성을 통해 사용자에게 다시 전달  

# 3. Deep Learning Review  
- 딥러닝은 블럭을 조립하는것과 비슷함  
- **모델 Building Blocks**  
  - Connectivity Patterns  
    - Fully-Connected  
    - Convolutional  
    - Dilated  
    - ...
  - Nonlinearity Modules  
    - ReLU  
    - Sigmoid  
    - Tanh  
    - GRU  
    - LSTM  
  - Loss Function  
    - Cross Entropy  
    - Adversarial  
    - Variational  
    - L1 & L2  
- **모델 학습 Blocks**  
  - Optimizer  
    - SGD  
    - Momentum  
    - RMSProp  
    - Adagrad  
    - Adam  
  - Hyper Parameters  
    - Learning rate  
    - Weight decay  
    - Layer size  
    - Batch size  
    - Dropout rate  
    - Weight initialization  
    - Data augmentation  
    - Gradient clipping  
    - Momentum

## 1) Multi-Layer Perceptron(MLP)   
- FC Layer와 비슷함

## 2) Convolutional Neural Networks
- 개념 정리 필요
- CNN in Audio!
  - audio는 채널이 없음
  - 2-D CNN 주로 사용
  - Sample CNN

## 3) RNN
 - Hidden State를 유지하면서 이전 출력을 입력으로 사용할 수 있는 신경망

## 4) LSTM

## 5) Attention
