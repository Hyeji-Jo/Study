# 0. 음성인식 모델의 역사  
음성인식으로 사용자 맥락 파악 -> 맥락에 맞는 음악 추천  

- **1950~1960년대: 초기 연구와 기초 기술**  
  - 1952년, Bell Labs의 Audrey: 가장 초기의 음성인식 시스템 중 하나로, 숫자 0부터 9까지의 음성을 인식할 수 있었습니다.  
  - 1960년대, IBM의 Shoebox: 단어 인식을 위한 시스템으로, 16개의 단어와 숫자를 인식할 수 있었습니다.  
- **1970~1980년대: 동적 시간 왜곡과 히든 마르코프 모델**  
  - 동적 시간 왜곡 (Dynamic Time Warping, DTW): 음성 신호의 시간적 변형을 허용하여 유사성을 측정하는 기법으로, 음성인식에서 널리 사용되었습니다.  
  - 히든 마르코프 모델 (Hidden Markov Model, HMM): 1970년대 후반에 도입되어 1980년대와 1990년대에 음성인식 시스템의 주류가 되었습니다. 음성의 통계적 모델링에 기반한 이 모델은 연속적인 음성을 인식하는 데 뛰어난 성능을 보였습니다.  
- **1990년대: 대규모 음성 데이터와 모델의 발전**  
  - 스피커 독립 음성인식 시스템: 다양한 사용자에게 적용될 수 있는 모델로, 대규모 데이터와 더욱 정교한 HMM이 사용되었습니다.  
  - 연속 음성 인식: 문맥을 고려하여 연속적인 음성을 인식할 수 있게 되었습니다. 이는 특히 IBM의 ViaVoice와 같은 상업용 제품에 적용되었습니다.  
- **2000년대: 통계적 모델과 신경망의 결합**  
  - 조건부 확률 모델 (Conditional Random Fields, CRF) 및 최대 엔트로피 모델: 음성인식의 정확도를 높이기 위해 사용되었습니다.  
  - 딥 뉴럴 네트워크 (DNN): 2000년대 후반부터 HMM과 DNN을 결합한 모델이 사용되기 시작하여, 음성 인식의 성능이 크게 향상되었습니다.  
- **2010년대 이후: 심층 신경망과 음성 비서의 발전**  
  - 딥러닝의 도입: 딥러닝 기술이 음성인식에 도입되면서 음성 인식의 정확도와 효율성이 크게 향상되었습니다. 구글의 음성 검색, 애플의 시리, 아마존의 알렉사 등 주요 음성 비서 서비스가 이 기술을 사용합니다.  
  - 엔드투엔드 모델: RNN, LSTM, GRU와 같은 순환 신경망이 사용되면서, 음성인식 시스템이 더욱 통합되고 정확해졌습니다.  
  - Transformer 기반 모델: 최근에는 Transformer 구조를 사용한 모델이 음성인식에 적용되고 있습니다. 특히, 구글의 WaveNet과 같은 모델이 높은 성능을 보이고 있습니다.  
  이처럼 음성인식 기술은 초기의 간단한 시스템에서부터 복잡한 신경망 기반의 모델에 이르기까지 지속적으로 발전해왔습니다. 최신 기술들은 점점 더 높은 정확도를 제공하며 다양한 응용 분야에서 사용되고 있습니다.  



# 1. Digital Signal Processing  
## Sound  
- 소리 = 진동으로 인한 공기의 압축  
- 압축이 얼마나 됬느냐 = Wave(파동)  
  - 진동하며 공간/매질을 전파해 나가는 현상  
- 소리에서 얻을 수 있는 물리량     
  - Phase(Degress of displacement) : 위상  
  - Amplitude(Intensity) : 진폭    
  - Frequency : 주파수  
- 물리 음향  
  - Intensity : 소리 진폭의 세기  
  - Frequency : 소리 떨림의 빠르기  
  - Tone-Color : 소리 파동의 모양  
- 심리 음향  
  - Loudness : 소리 크기  
  - Pitch : 음정, 소리의 높낮이 / 진동수  
  - Timbre : 음색, 소리 감각  
 
## Fourier Transform (푸리에 변환)   
- 임의의 입력 신호를 다양한 주파수를 갖는 주기함수(복수 지수함수)들의 합으로 분해하여 표현하는 것  
- 푸리에 변환의 결과값으로 주파수의 강도와 주파수의 위상을 얻게 됨  

# 2. Audio Task  
- Sound  
  - Speech Classification & Auto-tagging  
- Speech  
  - Speech Recognition(STT) - 음성 인식  
  - Speech Synthesis(TTS) - 음성 합성  
  - Speech Style Transfer(STS) - 음성 변환  

스마트 스피커의 경우 사용자가 말하는 것을 음성인식으로 들어 txt를 자연어 처리로 넘김  
자연어 처리팀에서 맞는 정보를 return해주고, 그 정보를 음성 합성을 통해 사용자에게 다시 전달  

# 3. Deep Learning Review  
- 딥러닝은 블럭을 조립하는것과 비슷함  
- **모델 Building Blocks**  
  - Connectivity Patterns  
    - Fully-Connected  
    - Convolutional  
    - Dilated  
    - ...
  - Nonlinearity Modules  
    - ReLU  
    - Sigmoid  
    - Tanh  
    - GRU  
    - LSTM  
  - Loss Function  
    - Cross Entropy  
    - Adversarial  
    - Variational  
    - L1 & L2  
- **모델 학습 Blocks**  
  - Optimizer  
    - SGD  
    - Momentum  
    - RMSProp  
    - Adagrad  
    - Adam  
  - Hyper Parameters  
    - Learning rate  
    - Weight decay  
    - Layer size  
    - Batch size  
    - Dropout rate  
    - Weight initialization  
    - Data augmentation  
    - Gradient clipping  
    - Momentum

## 1) Multi-Layer Perceptron(MLP)   
- FC Layer와 비슷함

## 2) Convolutional Neural Networks
- 개념 정리 필요
- CNN in Audio!
  - audio는 채널이 없음
  - 2-D CNN 주로 사용
  - Sample CNN

## 3) RNN
 - Hidden State를 유지하면서 이전 출력을 입력으로 사용할 수 있는 신경망

## 4) LSTM

## 5) Attention
